{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debiaser agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging \n",
    "\n",
    "from debiasing.llm.utils import LLMMessage\n",
    "from debiasing.llm.agent import Debiaser\n",
    "\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create an agent named `Debiaser` with the capabilities to debiasing a gender biased text. So the task is to process any text, detect which (if any) parts of the text contain a gender bias, and then proposed debiased alternatives for that text. For that purpose we will use two tools:\n",
    "\n",
    "1. `GENDER_BIAS_MULTI_LABEL_CLASSIFIER`: a kind of NER-multilabel classifier tool that detect text within a paragraph for a set of possible gender biases.\n",
    "\n",
    "1. `DEBIASER`: a kind of sequence-to-sequence transfer style for biased-to-debiased gender text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, **what is an agent?** A piece of code that use an LLM in chat completion mode, a bunch of tools, reasoning, planning, an a while loop to solve a given task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing is the capacity to detect when the LLM is using a tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-01-06 00:51:51 - debiasing.configs - INFO - LLM Anthropic response: {\"id\":\"msg_01HK3GJJEyKo72BnvRdzpaKu\",\"type\":\"message\",\"role\":\"assistant\",\"model\":\"claude-3-5-sonnet-20241022\",\"content\":[{\"type\":\"text\",\"text\":\"I'll help analyze this text for gender biases and then provide a debiased version. Let's first detect the biases present:\"},{\"type\":\"tool_use\",\"id\":\"toolu_01Cp8LFpjo3ukxrJNQqUkf3i\",\"name\":\"gender_bias_classifier\",\"input\":{\"bias_label\":[\"STEREOTYPING_BIAS\",\"SEXISM\"],\"bias_text\":[\"Debe ser profesora de preescolar porque enseña super bien sumas\",\"no creo que sea ingenieria porque a las mujeres no les gusta eso\"],\"score_label\":[0.95,0.98]}}],\"stop_reason\":\"tool_use\",\"stop_sequence\":null,\"usage\":{\"input_tokens\":1808,\"cache_creation_input_tokens\":0,\"cache_read_input_tokens\":0,\"output_tokens\":186}}\n",
      "2025-01-06 00:51:51 - debiasing.configs - INFO - LLM Response: {'id': 'msg_01HK3GJJEyKo72BnvRdzpaKu', 'type': 'message', 'role': 'assistant', 'model': 'claude-3-5-sonnet-20241022', 'content': [{'type': 'text', 'text': \"I'll help analyze this text for gender biases and then provide a debiased version. Let's first detect the biases present:\"}, {'type': 'tool_use', 'id': 'toolu_01Cp8LFpjo3ukxrJNQqUkf3i', 'name': 'gender_bias_classifier', 'input': {'bias_label': ['STEREOTYPING_BIAS', 'SEXISM'], 'bias_text': ['Debe ser profesora de preescolar porque enseña super bien sumas', 'no creo que sea ingenieria porque a las mujeres no les gusta eso'], 'score_label': [0.95, 0.98]}}], 'stop_reason': 'tool_use', 'stop_sequence': None, 'usage': {'input_tokens': 1808, 'cache_creation_input_tokens': 0, 'cache_read_input_tokens': 0, 'output_tokens': 186}}\n",
      "2025-01-06 00:51:51 - debiasing.configs - INFO - Debiaser tool detected\n",
      "2025-01-06 00:51:51 - debiasing.configs - INFO - Analyzing the previous text I have the following information about gender biases:\n",
      "The text 'Debe ser profesora de preescolar porque enseña super bien sumas' contains STEREOTYPING_BIAS with score 0.95\n",
      "The text 'no creo que sea ingenieria porque a las mujeres no les gusta eso' contains SEXISM with score 0.98\n",
      "\n",
      "2025-01-06 00:51:58 - debiasing.configs - INFO - LLM Anthropic response: {\"id\":\"msg_01Moi5xNTXiZHMmt51mykHV7\",\"type\":\"message\",\"role\":\"assistant\",\"model\":\"claude-3-5-sonnet-20241022\",\"content\":[{\"type\":\"text\",\"text\":\"I'll use the debiaser tool to create a gender-neutral version of the text that removes these stereotypical and sexist biases.\"},{\"type\":\"tool_use\",\"id\":\"toolu_01PNvnTXJfLH2Yr5DcxApbBj\",\"name\":\"debiaser\",\"input\":{\"debiasing_text\":\"Karen es muy buena enseñando. Tiene talento para explicar matemáticas como sumas básicas (2 + 3). Podría desempeñarse en cualquier campo profesional que desee, ya sea en educación o ingeniería, pues las habilidades y gustos no están determinados por el género.\",\"reasoning\":[\"Removed the diminutive 'karencita' which can be condescending and used the proper name 'Karen'\",\"Eliminated the assumption that teaching ability automatically means someone should be a preschool teacher\",\"Removed gender stereotyping about teaching being a feminine profession\",\"Eliminated the sexist assumption that women don't like engineering\",\"Reframed the text to focus on individual abilities and choices rather than gender-based assumptions\",\"Added a statement that reinforces that professional abilities and interests are not determined by gender\"]}}],\"stop_reason\":\"tool_use\",\"stop_sequence\":null,\"usage\":{\"input_tokens\":1909,\"cache_creation_input_tokens\":0,\"cache_read_input_tokens\":0,\"output_tokens\":299}}\n",
      "2025-01-06 00:51:58 - debiasing.configs - INFO - Removed the diminutive 'karencita' which can be condescending and used the proper name 'Karen'\n",
      "2025-01-06 00:51:58 - debiasing.configs - INFO - Eliminated the assumption that teaching ability automatically means someone should be a preschool teacher\n",
      "2025-01-06 00:51:58 - debiasing.configs - INFO - Removed gender stereotyping about teaching being a feminine profession\n",
      "2025-01-06 00:51:58 - debiasing.configs - INFO - Eliminated the sexist assumption that women don't like engineering\n",
      "2025-01-06 00:51:58 - debiasing.configs - INFO - Reframed the text to focus on individual abilities and choices rather than gender-based assumptions\n",
      "2025-01-06 00:51:58 - debiasing.configs - INFO - Added a statement that reinforces that professional abilities and interests are not determined by gender\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Karen es muy buena enseñando. Tiene talento para explicar matemáticas como sumas básicas (2 + 3). Podría desempeñarse en cualquier campo profesional que desee, ya sea en educación o ingeniería, pues las habilidades y gustos no están determinados por el género.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "debiaser = Debiaser(provider=\"anthropic\")\n",
    "\n",
    "input_text = (\n",
    "    \"La karencita es tan tierna. \"\n",
    "    \"Debe ser profesora de preescolar \"\n",
    "    \"porque enseña super bien sumas como 2 + 3. \"\n",
    "    \"Además no creo que sea ingenieria \"\n",
    "    \"porque a las mujeres no les gusta eso\"\n",
    ")\n",
    "\n",
    "# input_text = \"Hola, cómo estas?\"\n",
    "\n",
    "msgs = [\n",
    "    LLMMessage(\n",
    "        role=LLMMessage.MessageRole.USER,\n",
    "        content=input_text,\n",
    "    )\n",
    "]\n",
    "\n",
    "debiaser.execute_task(msgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "debiasing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
